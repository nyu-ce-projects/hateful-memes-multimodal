{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import cv2\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import random\n",
    "import tarfile\n",
    "import tempfile\n",
    "import warnings\n",
    "import timm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import pandas_path  # Path style access for pandas\n",
    "from tqdm import tqdm\n",
    "import torch                    \n",
    "import torchvision\n",
    "import fasttext\n",
    "import pandas_path\n",
    "from transformers import DistilBertModel, DistilBertConfig, DistilBertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path.cwd().parent / \"Data\" / \"hateful_memes\"\n",
    "img_tar_path = data_dir / \"img.tar.gz\"\n",
    "train_path = data_dir / \"train.jsonl\"\n",
    "dev_path = data_dir / \"dev_seen.jsonl\"\n",
    "test_path = data_dir / \"test_seen.jsonl.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8291</td>\n",
       "      <td>img/08291.png</td>\n",
       "      <td>1</td>\n",
       "      <td>white people is this a shooting range</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46971</td>\n",
       "      <td>img/46971.png</td>\n",
       "      <td>1</td>\n",
       "      <td>bravery at its finest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3745</td>\n",
       "      <td>img/03745.png</td>\n",
       "      <td>1</td>\n",
       "      <td>your order comes to $37.50 and your white priv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83745</td>\n",
       "      <td>img/83745.png</td>\n",
       "      <td>1</td>\n",
       "      <td>it is time.. to send these parasites back to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80243</td>\n",
       "      <td>img/80243.png</td>\n",
       "      <td>1</td>\n",
       "      <td>mississippi wind chime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>83675</td>\n",
       "      <td>img/83675.png</td>\n",
       "      <td>0</td>\n",
       "      <td>i'm gonna be like phelps one day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>37198</td>\n",
       "      <td>img/37198.png</td>\n",
       "      <td>0</td>\n",
       "      <td>when you're so relaxed you can feel yourself g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>48670</td>\n",
       "      <td>img/48670.png</td>\n",
       "      <td>0</td>\n",
       "      <td>look at this sandwich maker club i found on wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>9863</td>\n",
       "      <td>img/09863.png</td>\n",
       "      <td>0</td>\n",
       "      <td>diverse group of women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>97320</td>\n",
       "      <td>img/97320.png</td>\n",
       "      <td>0</td>\n",
       "      <td>\"when your dishwasher is broken so you take it...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id            img  label  \\\n",
       "0     8291  img/08291.png      1   \n",
       "1    46971  img/46971.png      1   \n",
       "2     3745  img/03745.png      1   \n",
       "3    83745  img/83745.png      1   \n",
       "4    80243  img/80243.png      1   \n",
       "..     ...            ...    ...   \n",
       "495  83675  img/83675.png      0   \n",
       "496  37198  img/37198.png      0   \n",
       "497  48670  img/48670.png      0   \n",
       "498   9863  img/09863.png      0   \n",
       "499  97320  img/97320.png      0   \n",
       "\n",
       "                                                  text  \n",
       "0                white people is this a shooting range  \n",
       "1                                bravery at its finest  \n",
       "2    your order comes to $37.50 and your white priv...  \n",
       "3    it is time.. to send these parasites back to t...  \n",
       "4                               mississippi wind chime  \n",
       "..                                                 ...  \n",
       "495                   i'm gonna be like phelps one day  \n",
       "496  when you're so relaxed you can feel yourself g...  \n",
       "497  look at this sandwich maker club i found on wi...  \n",
       "498                             diverse group of women  \n",
       "499  \"when your dishwasher is broken so you take it...  \n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_path_frame = pd.read_json(dev_path, lines=True)\n",
    "dev_path_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/scratch/ps4364/HM/Data/hateful_memes/train.jsonl')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42953</td>\n",
       "      <td>img/42953.png</td>\n",
       "      <td>0</td>\n",
       "      <td>its their character not their color that matters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23058</td>\n",
       "      <td>img/23058.png</td>\n",
       "      <td>0</td>\n",
       "      <td>don't be afraid to love again everyone is not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13894</td>\n",
       "      <td>img/13894.png</td>\n",
       "      <td>0</td>\n",
       "      <td>putting bows on your pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37408</td>\n",
       "      <td>img/37408.png</td>\n",
       "      <td>0</td>\n",
       "      <td>i love everything and everybody! except for sq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82403</td>\n",
       "      <td>img/82403.png</td>\n",
       "      <td>0</td>\n",
       "      <td>everybody loves chocolate chip cookies, even h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8495</th>\n",
       "      <td>10423</td>\n",
       "      <td>img/10423.png</td>\n",
       "      <td>1</td>\n",
       "      <td>nobody wants to hang auschwitz me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8496</th>\n",
       "      <td>98203</td>\n",
       "      <td>img/98203.png</td>\n",
       "      <td>1</td>\n",
       "      <td>when god grants you a child after 20 years of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8497</th>\n",
       "      <td>36947</td>\n",
       "      <td>img/36947.png</td>\n",
       "      <td>1</td>\n",
       "      <td>gays on social media: equality! body positivit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8498</th>\n",
       "      <td>16492</td>\n",
       "      <td>img/16492.png</td>\n",
       "      <td>1</td>\n",
       "      <td>having a bad day? you could be a siamese twin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8499</th>\n",
       "      <td>15937</td>\n",
       "      <td>img/15937.png</td>\n",
       "      <td>1</td>\n",
       "      <td>i hate muslims too they take their religion to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id            img  label  \\\n",
       "0     42953  img/42953.png      0   \n",
       "1     23058  img/23058.png      0   \n",
       "2     13894  img/13894.png      0   \n",
       "3     37408  img/37408.png      0   \n",
       "4     82403  img/82403.png      0   \n",
       "...     ...            ...    ...   \n",
       "8495  10423  img/10423.png      1   \n",
       "8496  98203  img/98203.png      1   \n",
       "8497  36947  img/36947.png      1   \n",
       "8498  16492  img/16492.png      1   \n",
       "8499  15937  img/15937.png      1   \n",
       "\n",
       "                                                   text  \n",
       "0      its their character not their color that matters  \n",
       "1     don't be afraid to love again everyone is not ...  \n",
       "2                              putting bows on your pet  \n",
       "3     i love everything and everybody! except for sq...  \n",
       "4     everybody loves chocolate chip cookies, even h...  \n",
       "...                                                 ...  \n",
       "8495                  nobody wants to hang auschwitz me  \n",
       "8496  when god grants you a child after 20 years of ...  \n",
       "8497  gays on social media: equality! body positivit...  \n",
       "8498  having a bad day? you could be a siamese twin ...  \n",
       "8499  i hate muslims too they take their religion to...  \n",
       "\n",
       "[8500 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples_frame = pd.read_json(train_path, lines=True)\n",
    "train_samples_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_valid_dfs(path):\n",
    "    dataframe = pd.read_json(path,lines=True)\n",
    "    max_id = dataframe[\"id\"].max() + 1 if not False else 100\n",
    "    image_ids = np.arange(0, max_id)\n",
    "    np.random.seed(42)\n",
    "    valid_ids = np.random.choice(\n",
    "        image_ids, size=int(0.2 * len(image_ids)), replace=False\n",
    "    )\n",
    "    train_ids = [id_ for id_ in image_ids if id_ not in valid_ids]\n",
    "    train_dataframe = dataframe[dataframe[\"id\"].isin(train_ids)].reset_index(drop=True)\n",
    "    valid_dataframe = dataframe[dataframe[\"id\"].isin(valid_ids)].reset_index(drop=True)\n",
    "    return train_dataframe, valid_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,val=make_train_valid_dfs(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLIPDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_filenames, captions,labels, tokenizer, transforms):\n",
    "        \"\"\"\n",
    "        image_filenames and cpations must have the same length; so, if there are\n",
    "        multiple captions for each image, the image_filenames must have repetitive\n",
    "        file names \n",
    "        \"\"\"\n",
    "\n",
    "        self.image_filenames = image_filenames\n",
    "        self.captions = list(captions)\n",
    "        self.labels = list(labels)\n",
    "        self.encoded_captions = tokenizer(\n",
    "            list(captions), padding=True, truncation=True, max_length=200\n",
    "        )\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            key: torch.tensor(values[idx])\n",
    "            for key, values in self.encoded_captions.items()\n",
    "        }\n",
    "        label = torch.Tensor([list(self.labels)]).long().squeeze()\n",
    "        image = cv2.imread(f\"{CFG.image_path}/{self.image_filenames[idx]}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = self.transforms(image=image)['image']\n",
    "        item['image'] = torch.tensor(image).permute(2, 0, 1).float()\n",
    "        item['caption'] = self.captions[idx]\n",
    "        item['label'] = self.labels[idx]\n",
    "\n",
    "        return item\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.captions)\n",
    "\n",
    "\n",
    "\n",
    "def get_transforms(mode=\"train\"):\n",
    "    if mode == \"train\":\n",
    "        return A.Compose(\n",
    "            [\n",
    "                A.Resize(CFG.size, CFG.size, always_apply=True),\n",
    "                A.Normalize(max_pixel_value=255.0, always_apply=True),\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        return A.Compose(\n",
    "            [\n",
    "                A.Resize(CFG.size, CFG.size, always_apply=True),\n",
    "                A.Normalize(max_pixel_value=255.0, always_apply=True),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "transforms=A.Compose([A.Resize(384, 384, always_apply=True),\n",
    "                      A.Normalize(max_pixel_value=255.0, always_apply=True),])\n",
    "dataset = CLIPDataset(train[\"img\"].values,train[\"text\"].values,train[\"label\"].values,tokenizer=tokenizer,transforms=transforms,)\n",
    "dataloader = torch.utils.data.DataLoader(dataset,batch_size=4,num_workers=3,shuffle=True)\n",
    "\n",
    "val_dataset = CLIPDataset(val[\"img\"].values,val[\"text\"].values,val[\"label\"].values,tokenizer=tokenizer,transforms=transforms,)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset,batch_size=4,num_workers=3,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"/scratch/ps4364/HM/Data/hateful_memes\"\n",
    "captions_path = \"/scratch/ps4364/HM/Data/hateful_memes\"\n",
    "class CFG:\n",
    "    debug = False\n",
    "    image_path = image_path\n",
    "    captions_path = captions_path\n",
    "    batch_size = 32\n",
    "    num_workers = 2\n",
    "    head_lr = 1e-3\n",
    "    image_encoder_lr = 1e-4\n",
    "    text_encoder_lr = 1e-5\n",
    "    weight_decay = 1e-3\n",
    "    patience = 1\n",
    "    factor = 0.8\n",
    "    epochs = 4\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model_name = 'resnet50'\n",
    "    image_embedding = 2048\n",
    "    text_encoder_model = \"distilbert-base-uncased\"\n",
    "    text_embedding = 768\n",
    "    text_tokenizer = \"distilbert-base-uncased\"\n",
    "    max_length = 200\n",
    "\n",
    "    pretrained = True # for both image encoder and text encoder\n",
    "    trainable = True # for both image encoder and text encoder\n",
    "    temperature = 1.0\n",
    "\n",
    "    # image size\n",
    "    size = 384\n",
    "\n",
    "    # for projection head; used for both image and text encoders\n",
    "    num_projection_layers = 1\n",
    "    projection_dim = 256 \n",
    "    dropout = 0.1\n",
    "    \n",
    "class CLIPModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        temperature=CFG.temperature,\n",
    "        image_embedding=CFG.image_embedding,\n",
    "        text_embedding=CFG.text_embedding,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.image_encoder = ImageEncoder()\n",
    "        self.text_encoder = TextEncoder()\n",
    "        self.image_projection = ProjectionHead(embedding_dim=image_embedding)\n",
    "        self.text_projection = ProjectionHead(embedding_dim=text_embedding)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # Getting Image and Text Features\n",
    "        image_features = self.image_encoder(batch[\"image\"])\n",
    "        text_features = self.text_encoder(\n",
    "            input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"]\n",
    "        )\n",
    "        # Getting Image and Text Embeddings (with same dimension)\n",
    "        image_embeddings = self.image_projection(image_features)\n",
    "        text_embeddings = self.text_projection(text_features)\n",
    "\n",
    "        # Calculating the Loss\n",
    "        logits = (text_embeddings @ image_embeddings.T) / self.temperature\n",
    "        images_similarity = image_embeddings @ image_embeddings.T\n",
    "        texts_similarity = text_embeddings @ text_embeddings.T\n",
    "        targets = F.softmax(\n",
    "            (images_similarity + texts_similarity) / 2 * self.temperature, dim=-1\n",
    "        )\n",
    "        texts_loss = cross_entropy(logits, targets, reduction='none')\n",
    "        images_loss = cross_entropy(logits.T, targets.T, reduction='none')\n",
    "        loss =  (images_loss + texts_loss) / 2.0 # shape: (batch_size)\n",
    "        return loss.mean()\n",
    "\n",
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim,\n",
    "        projection_dim=CFG.projection_dim,\n",
    "        dropout=CFG.dropout\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.projection = nn.Linear(embedding_dim, projection_dim)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.fc = nn.Linear(projection_dim, projection_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(projection_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        projected = self.projection(x)\n",
    "        x = self.gelu(projected)\n",
    "        x = self.fc(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x + projected\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "    \n",
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, model_name=CFG.text_encoder_model, pretrained=CFG.pretrained, trainable=CFG.trainable):\n",
    "        super().__init__()\n",
    "        if pretrained:\n",
    "            self.model = DistilBertModel.from_pretrained(model_name)\n",
    "        else:\n",
    "            self.model = DistilBertModel(config=DistilBertConfig())\n",
    "            \n",
    "        for p in self.model.parameters():\n",
    "            p.requires_grad = trainable\n",
    "\n",
    "        # we are using the CLS token hidden representation as the sentence's embedding\n",
    "        self.target_token_idx = 0\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = output.last_hidden_state\n",
    "        return last_hidden_state[:, self.target_token_idx, :]\n",
    "class ImageEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encode images to a fixed size vector\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, model_name=CFG.model_name, pretrained=CFG.pretrained, trainable=CFG.trainable\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(\n",
    "            model_name, pretrained, num_classes=0, global_pool=\"avg\"\n",
    "        )\n",
    "        for p in self.model.parameters():\n",
    "            p.requires_grad = trainable\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageAndVisionConcat(torch.nn.Module):\n",
    "    def __init__(self,language_module,vision_module,\n",
    "                 language_feature_dim=300,vision_feature_dim=300,fusion_output_size=256,dropout_p=0.1,num_classes=1000):\n",
    "        super(LanguageAndVisionConcat, self).__init__()\n",
    "        self.language_module = language_module\n",
    "        self.language_adder=nn.Linear(768,300)\n",
    "        self.vision_module = vision_module\n",
    "        self.vision_adder=nn.Linear(512,300)\n",
    "        self.fusion = torch.nn.Linear(\n",
    "            in_features=(language_feature_dim + vision_feature_dim), \n",
    "            out_features=fusion_output_size\n",
    "        )\n",
    "        self.fc = torch.nn.Linear(\n",
    "            in_features=fusion_output_size, \n",
    "            out_features=num_classes\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        language_op1=self.language_module(x['input_ids'].cuda(),x['attention_mask'])\n",
    "        language_op = self.language_adder(language_op1)\n",
    "        \n",
    "        vision_op1=self.vision_module(x['image'])\n",
    "        vision_op = self.vision_adder(vision_op1)\n",
    "        combined = torch.cat(\n",
    "            [language_op, vision_op], dim=1\n",
    "        )\n",
    "        fused = torch.nn.functional.relu(\n",
    "            self.fusion(combined)\n",
    "            )\n",
    "        \n",
    "        logits = self.fc(fused)\n",
    "        #pred = torch.nn.functional.softmax(logits)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_cnn = LanguageAndVisionConcat(language_module=TextEncoder(),vision_module=timm.create_model('resnet50',  True, num_classes=512)).cuda()\n",
    "model_vit = LanguageAndVisionConcat(language_module=TextEncoder(),vision_module=timm.create_model('vit_base_patch16_384',  True,num_classes=512)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageAndVisionConcat(\n",
       "  (language_module): TextEncoder(\n",
       "    (model): DistilBertModel(\n",
       "      (embeddings): Embeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (transformer): Transformer(\n",
       "        (layer): ModuleList(\n",
       "          (0): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (activation): GELUActivation()\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (activation): GELUActivation()\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (activation): GELUActivation()\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (activation): GELUActivation()\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (activation): GELUActivation()\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (activation): GELUActivation()\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (language_adder): Linear(in_features=768, out_features=300, bias=True)\n",
       "  (vision_module): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (fc): Linear(in_features=2048, out_features=512, bias=True)\n",
       "  )\n",
       "  (vision_adder): Linear(in_features=512, out_features=300, bias=True)\n",
       "  (fusion): Linear(in_features=600, out_features=256, bias=True)\n",
       "  (fc): Linear(in_features=256, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchcontrib.optim import SWA\n",
    "params_cnn = [\n",
    "        {\"params\": model_cnn.vision_module.parameters(), \"lr\": CFG.image_encoder_lr},\n",
    "        {\"params\": model_cnn.language_module.parameters(), \"lr\": CFG.text_encoder_lr},\n",
    "        {\"params\": itertools.chain(\n",
    "            model_cnn.vision_adder.parameters(), model_cnn.language_adder.parameters()\n",
    "        ), \"lr\": CFG.head_lr, \"weight_decay\": CFG.weight_decay}\n",
    "    ]\n",
    "optimizer_cnn = torch.optim.AdamW(params_cnn, weight_decay=0.)\n",
    "\n",
    "params_vit = [\n",
    "        {\"params\": model_vit.vision_module.parameters(), \"lr\": CFG.image_encoder_lr},\n",
    "        {\"params\": model_vit.language_module.parameters(), \"lr\": CFG.text_encoder_lr},\n",
    "        {\"params\": itertools.chain(\n",
    "            model_vit.vision_adder.parameters(), model_vit.language_adder.parameters()\n",
    "        ), \"lr\": CFG.head_lr, \"weight_decay\": CFG.weight_decay}\n",
    "    ]\n",
    "optimizer_vit = torch.optim.AdamW(params_vit, weight_decay=0.)\n",
    "\n",
    "\n",
    "scheduler_cnn = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer_cnn, mode=\"min\", patience=CFG.patience, factor=CFG.factor\n",
    "    )\n",
    "scheduler_vit = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer_vit, mode=\"min\", patience=CFG.patience, factor=CFG.factor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(x, y):\n",
    "    x_noise=(torch.normal(10e-6, 10e-9, size=(x.size()))).to(device)\n",
    "    x=x+x_noise\n",
    "    x =  torch.nn.functional.normalize(x, dim=-1, p=2)\n",
    "    y_noise=(torch.normal(10e-10, 10e-15, size=(y.size()))).to(device)\n",
    "    y=y+y_noise\n",
    "    y =  torch.nn.functional.normalize(y, dim=-1, p=2)\n",
    "    return 2 - 2 * (x * y).sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def ssl_train_model(train_loader,model_vit,optimizer_vit,scheduler_vit,model_cnn,optimizer_cnn,scheduler_cnn,num_epochs):\n",
    "    writer = SummaryWriter()\n",
    "    phase = 'train'\n",
    "    model_cnn.train()\n",
    "    model_vit.train()\n",
    "    f1_score_vit=0\n",
    "    best_loss=math.inf\n",
    "    for i in tqdm(range(num_epochs)):\n",
    "        #tqdm_object = tqdm(train_loader, total=len(train_loader))\n",
    "        total_loss=0\n",
    "        for batch in train_loader:\n",
    "            optimizer_cnn.zero_grad()\n",
    "            optimizer_vit.zero_grad()\n",
    "            batch = {k: v.to(CFG.device) for k, v in batch.items() if k != \"caption\"}\n",
    "            pred_vit = model_vit(batch)\n",
    "            pred_cnn = model_cnn(batch)\n",
    "            model_sim_loss=loss_fn(pred_cnn,pred_vit)\n",
    "            loss = model_sim_loss.mean()\n",
    "            loss.backward()\n",
    "            optimizer_cnn.step()\n",
    "            optimizer_vit.step()\n",
    "            scheduler_cnn.step(loss)\n",
    "            scheduler_vit.step(loss)\n",
    "            total_loss+=loss.item()\n",
    "        print('For -',i,'Loss:',total_loss)\n",
    "        if total_loss<best_loss:\n",
    "            best_loss=total_loss\n",
    "            print(\"Saving!\")\n",
    "            torch.save(model_cnn,'./vitb16-r50-CNNPART-CASS-BERT-384-logits-v2-optimparams-100-nodp-agg.pt')\n",
    "            torch.save(model_vit,'./vitb16-r50-VITPART-CASS-BERT-384-logits-v2-optimparams-100-nodp-agg.pt')\n",
    "    \n",
    "        writer.add_scalar(\"Self-Supervised Loss/train\", total_loss, i)\n",
    "    writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CASS multimodally\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 0 Loss: 1401.7228937149048\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [18:19<30:14:21, 1099.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 1 Loss: 1395.3502717614174\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [36:33<29:50:34, 1096.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 2 Loss: 1394.375661432743\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [54:48<29:31:31, 1095.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 3 Loss: 1393.129042685032\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [1:13:02<29:11:43, 1094.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 4 Loss: 1391.6246501207352\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [1:31:19<28:54:44, 1095.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 5 Loss: 1390.2674586176872\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [1:49:32<28:35:28, 1094.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 6 Loss: 1388.4711526036263\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [2:07:46<28:16:26, 1094.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 7 Loss: 1385.8926261663437\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [2:26:00<27:58:03, 1094.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 8 Loss: 1383.2072128653526\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [2:44:15<27:39:53, 1094.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 9 Loss: 1381.846919119358\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [3:02:27<27:20:37, 1093.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 10 Loss: 1380.2774810791016\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [3:20:36<27:00:13, 1092.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 11 Loss: 1378.6399245858192\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [3:39:25<26:58:33, 1103.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 12 Loss: 1377.711595594883\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [3:58:12<26:50:29, 1110.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 13 Loss: 1377.1848046183586\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [4:16:23<26:23:29, 1104.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 14 Loss: 1376.795661687851\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [4:34:35<25:59:25, 1100.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 15 Loss: 1376.4341621398926\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [4:52:46<25:37:03, 1097.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 16 Loss: 1376.1113726496696\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [5:10:58<25:16:21, 1096.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 17 Loss: 1375.8849658370018\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [5:29:10<24:56:28, 1094.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 18 Loss: 1375.4644347429276\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [5:47:22<24:36:45, 1093.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 19 Loss: 1375.1644029021263\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [6:05:34<24:17:57, 1093.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 20 Loss: 1374.9691153764725\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [6:23:46<23:59:01, 1092.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 21 Loss: 1374.8242146372795\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [6:41:57<23:40:09, 1092.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 22 Loss: 1374.7057619094849\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [7:00:08<23:21:29, 1092.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 23 Loss: 1374.6320691108704\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [7:18:19<23:02:42, 1091.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 24 Loss: 1374.5086783766747\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [7:36:32<22:44:59, 1091.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 25 Loss: 1374.426366865635\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [7:54:44<22:27:01, 1092.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 26 Loss: 1374.344474375248\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [8:12:57<22:09:03, 1092.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 27 Loss: 1374.2767978906631\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [8:31:09<21:50:33, 1092.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 28 Loss: 1374.221900999546\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [8:49:21<21:32:11, 1092.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 29 Loss: 1374.1555160284042\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [9:07:31<21:13:37, 1091.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 30 Loss: 1374.103799521923\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [9:25:39<20:53:55, 1090.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 31 Loss: 1374.0545480251312\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [9:43:46<20:34:36, 1089.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 32 Loss: 1373.9855906963348\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [10:01:55<20:16:32, 1089.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 33 Loss: 1372.8932318091393\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [10:20:07<19:59:06, 1090.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 34 Loss: 1372.6250128746033\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [10:38:20<19:41:54, 1091.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 35 Loss: 1372.5533174872398\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [10:56:31<19:23:36, 1090.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 36 Loss: 1372.492716372013\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [11:14:43<19:05:46, 1091.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 37 Loss: 1372.3769441246986\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [11:32:55<18:47:52, 1091.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 38 Loss: 1372.3159744143486\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [11:51:08<18:30:10, 1091.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 39 Loss: 1372.2871387004852\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [12:09:21<18:12:19, 1092.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 40 Loss: 1372.2576509714127\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [12:27:32<17:53:50, 1092.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 41 Loss: 1372.2419738769531\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [12:45:42<17:35:01, 1091.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 42 Loss: 1372.2057368159294\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [13:03:53<17:16:38, 1091.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 43 Loss: 1372.1796392202377\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [13:22:06<16:58:50, 1091.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 44 Loss: 1372.157048046589\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [13:40:17<16:40:39, 1091.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 45 Loss: 1372.1317014694214\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [13:58:28<16:22:16, 1091.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 46 Loss: 1372.1194226145744\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [14:16:39<16:03:47, 1091.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 47 Loss: 1372.0862981677055\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [14:34:54<15:46:39, 1092.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 48 Loss: 1372.0657296180725\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [14:53:07<15:28:42, 1092.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 49 Loss: 1371.7513354420662\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [15:11:19<15:10:26, 1092.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 50 Loss: 1371.5716944336891\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [15:29:31<14:52:01, 1092.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 51 Loss: 1371.5393055677414\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [15:47:43<14:33:41, 1092.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 52 Loss: 1371.5154995322227\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [16:05:56<14:15:37, 1092.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 53 Loss: 1371.5006140470505\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [16:24:06<13:57:01, 1091.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 54 Loss: 1371.4881650209427\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [16:42:16<13:38:30, 1091.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 55 Loss: 1371.4660311937332\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 56/100 [17:00:28<13:20:22, 1091.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 56 Loss: 1371.457798242569\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [17:18:39<13:02:06, 1091.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For - 57 Loss: 1371.4425690174103\n",
      "Saving!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 58/100 [17:36:50<12:43:54, 1091.31s/it]"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "print('Training CASS multimodally')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "ssl_train_model(dataloader,model_vit,optimizer_vit,scheduler_vit,model_cnn,optimizer_cnn,scheduler_cnn,num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for batch in tqdm(dataloader):\n",
    "    batch = {k: v.to(CFG.device) for k, v in batch.items() if k != \"caption\"}\n",
    "    pred_vit = model_vit(batch)\n",
    "    pred_cnn = model_cnn(batch)\n",
    "    #loss=torch.nn.CrossEntropyLoss(pred_cnn,softmax(pred_vit))\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pranav_oct",
   "language": "python",
   "name": "pranav_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
